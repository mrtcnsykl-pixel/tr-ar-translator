import streamlit as st
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
import torch

# Sayfa tasarÄ±mÄ±
st.set_page_config(page_title="TR-AR Ã‡eviri", page_icon="ğŸŒ")

@st.cache_resource
def load_model():
    # Senin Hugging Face model kimliÄŸin
    model_id = "Saykal/tr-ar-translator-model" 
    
    tokenizer = AutoTokenizer.from_pretrained(model_id)
    # Ãœcretsiz sunucularda GPU olmadÄ±ÄŸÄ± iÃ§in CPU kullanÄ±yoruz
    model = AutoModelForSeq2SeqLM.from_pretrained(model_id).to("cpu")
    return tokenizer, model

st.title("ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e - ArapÃ§a Ã‡eviri ğŸ‡¦ğŸ‡ª")
st.markdown("Hugging Face Ã¼zerinden Ã§alÄ±ÅŸan yapay zeka modeli.")

try:
    tokenizer, model = load_model()
    
    user_input = st.text_area("Ã‡evrilecek metni yazÄ±n:", height=100)

    if st.button("Ã‡evir"):
        if user_input.strip():
            with st.spinner('Ã‡evriliyor...'):
                inputs = tokenizer(user_input, return_tensors="pt", padding=True, truncation=True, max_length=128)
                with torch.no_grad():
                    generated_tokens = model.generate(
                        **inputs,
                        max_length=128,
                        num_beams=5
                    )
                translation = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)
                st.subheader("SonuÃ§:")
                st.success(translation)
        else:
            st.warning("LÃ¼tfen bir metin girin.")
except Exception as e:
    st.error(f"Hata oluÅŸtu: {e}")
